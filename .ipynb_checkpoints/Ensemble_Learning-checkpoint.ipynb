{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa1ec5e-ad24-43c4-96b7-24fc18ca918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before preprocessing:\n",
      "Numeric: 51\n",
      "Categorical: 43\n",
      "Year: 3\n",
      "\n",
      "Categorical feature encoding details:\n",
      "MSZoning: 5 categories, 4 encoded features\n",
      "Street: 2 categories, 1 encoded features\n",
      "Alley: 3 categories, 2 encoded features\n",
      "LotShape: 4 categories, 3 encoded features\n",
      "LandContour: 4 categories, 3 encoded features\n",
      "Utilities: 2 categories, 1 encoded features\n",
      "LotConfig: 5 categories, 4 encoded features\n",
      "LandSlope: 3 categories, 2 encoded features\n",
      "Neighborhood: 10 categories, 9 encoded features\n",
      "Condition1: 9 categories, 8 encoded features\n",
      "Condition2: 8 categories, 7 encoded features\n",
      "BldgType: 5 categories, 4 encoded features\n",
      "HouseStyle: 8 categories, 7 encoded features\n",
      "RoofStyle: 6 categories, 5 encoded features\n",
      "RoofMatl: 8 categories, 7 encoded features\n",
      "Exterior1st: 10 categories, 9 encoded features\n",
      "Exterior2nd: 10 categories, 9 encoded features\n",
      "MasVnrType: 4 categories, 3 encoded features\n",
      "ExterQual: 4 categories, 3 encoded features\n",
      "ExterCond: 5 categories, 4 encoded features\n",
      "Foundation: 6 categories, 5 encoded features\n",
      "BsmtQual: 5 categories, 4 encoded features\n",
      "BsmtCond: 5 categories, 4 encoded features\n",
      "BsmtExposure: 5 categories, 4 encoded features\n",
      "BsmtFinType1: 7 categories, 6 encoded features\n",
      "BsmtFinType2: 7 categories, 6 encoded features\n",
      "Heating: 6 categories, 5 encoded features\n",
      "HeatingQC: 5 categories, 4 encoded features\n",
      "CentralAir: 2 categories, 1 encoded features\n",
      "Electrical: 6 categories, 5 encoded features\n",
      "KitchenQual: 4 categories, 3 encoded features\n",
      "Functional: 7 categories, 6 encoded features\n",
      "FireplaceQu: 6 categories, 5 encoded features\n",
      "GarageType: 7 categories, 6 encoded features\n",
      "GarageFinish: 4 categories, 3 encoded features\n",
      "GarageQual: 6 categories, 5 encoded features\n",
      "GarageCond: 6 categories, 5 encoded features\n",
      "PavedDrive: 3 categories, 2 encoded features\n",
      "PoolQC: 4 categories, 3 encoded features\n",
      "Fence: 5 categories, 4 encoded features\n",
      "MiscFeature: 5 categories, 4 encoded features\n",
      "SaleType: 9 categories, 8 encoded features\n",
      "SaleCondition: 6 categories, 5 encoded features\n",
      "\n",
      "Number of features after preprocessing:\n",
      "Numeric: 51\n",
      "Categorical (one-hot encoded): 198\n",
      "Year: 3\n",
      "\n",
      "Total number of features: 252\n",
      "Number of columns in preprocessed data: 252\n",
      "\n",
      "Final validation:\n",
      "Shape after preprocessing: (1460, 252)\n",
      "Missing values after preprocessing: 0\n",
      "Number of features before preprocessing:\n",
      "Numeric: 51\n",
      "Categorical: 43\n",
      "Year: 3\n",
      "\n",
      "Categorical feature encoding details:\n",
      "MSZoning: 5 categories, 4 encoded features\n",
      "Street: 2 categories, 1 encoded features\n",
      "Alley: 3 categories, 2 encoded features\n",
      "LotShape: 4 categories, 3 encoded features\n",
      "LandContour: 4 categories, 3 encoded features\n",
      "Utilities: 2 categories, 1 encoded features\n",
      "LotConfig: 5 categories, 4 encoded features\n",
      "LandSlope: 3 categories, 2 encoded features\n",
      "Neighborhood: 10 categories, 9 encoded features\n",
      "Condition1: 9 categories, 8 encoded features\n",
      "Condition2: 8 categories, 7 encoded features\n",
      "BldgType: 5 categories, 4 encoded features\n",
      "HouseStyle: 8 categories, 7 encoded features\n",
      "RoofStyle: 6 categories, 5 encoded features\n",
      "RoofMatl: 8 categories, 7 encoded features\n",
      "Exterior1st: 10 categories, 9 encoded features\n",
      "Exterior2nd: 10 categories, 9 encoded features\n",
      "MasVnrType: 4 categories, 3 encoded features\n",
      "ExterQual: 4 categories, 3 encoded features\n",
      "ExterCond: 5 categories, 4 encoded features\n",
      "Foundation: 6 categories, 5 encoded features\n",
      "BsmtQual: 5 categories, 4 encoded features\n",
      "BsmtCond: 5 categories, 4 encoded features\n",
      "BsmtExposure: 5 categories, 4 encoded features\n",
      "BsmtFinType1: 7 categories, 6 encoded features\n",
      "BsmtFinType2: 7 categories, 6 encoded features\n",
      "Heating: 6 categories, 5 encoded features\n",
      "HeatingQC: 5 categories, 4 encoded features\n",
      "CentralAir: 2 categories, 1 encoded features\n",
      "Electrical: 6 categories, 5 encoded features\n",
      "KitchenQual: 4 categories, 3 encoded features\n",
      "Functional: 7 categories, 6 encoded features\n",
      "FireplaceQu: 6 categories, 5 encoded features\n",
      "GarageType: 7 categories, 6 encoded features\n",
      "GarageFinish: 4 categories, 3 encoded features\n",
      "GarageQual: 6 categories, 5 encoded features\n",
      "GarageCond: 6 categories, 5 encoded features\n",
      "PavedDrive: 3 categories, 2 encoded features\n",
      "PoolQC: 4 categories, 3 encoded features\n",
      "Fence: 5 categories, 4 encoded features\n",
      "MiscFeature: 5 categories, 4 encoded features\n",
      "SaleType: 9 categories, 8 encoded features\n",
      "SaleCondition: 6 categories, 5 encoded features\n",
      "\n",
      "Number of features after preprocessing:\n",
      "Numeric: 51\n",
      "Categorical (one-hot encoded): 198\n",
      "Year: 3\n",
      "\n",
      "Total number of features: 252\n",
      "Number of columns in preprocessed data: 252\n",
      "Number of features: 252\n",
      "First 10 feature names: ['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF']\n",
      "Last 10 feature names: ['SaleType_Oth', 'SaleType_WD', 'SaleCondition_AdjLand', 'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal', 'SaleCondition_Partial', 'YearBuilt', 'YearRemodAdd', 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and engineering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Removed: import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "\n",
    "class OutlierCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "        self.lower_bounds = None\n",
    "        self.upper_bounds = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.lower_bounds = np.quantile(X, self.lower_quantile, axis=0)\n",
    "        self.upper_bounds = np.quantile(X, self.upper_quantile, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.clip(X, self.lower_bounds, self.upper_bounds)\n",
    "\n",
    "class YearConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.min_year = None\n",
    "        self.max_year = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_flat = X.ravel() if X.ndim > 1 else X\n",
    "        self.min_year = np.min(X_flat)\n",
    "        self.max_year = min(np.max(X_flat), pd.Timestamp.now().year)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_numeric = pd.to_numeric(X.ravel() if X.ndim > 1 else X, errors='coerce')\n",
    "        X_clipped = np.clip(X_numeric, self.min_year, self.max_year)\n",
    "        return X_clipped.reshape(X.shape)\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Create new features\n",
    "        X['TotalSF'] = X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']\n",
    "        \n",
    "        current_year = pd.Timestamp.now().year\n",
    "        X['HouseAge'] = current_year - X['YearBuilt']\n",
    "        X['TimeSinceRemodel'] = current_year - X['YearRemodAdd']\n",
    "        \n",
    "        X['TotalBathrooms'] = X['FullBath'] + (0.5 * X['HalfBath']) + X['BsmtFullBath'] + (0.5 * X['BsmtHalfBath'])\n",
    "        X['IsNewHouse'] = (X['YearBuilt'] == X['YrSold']).astype(int)\n",
    "        X['HasPool'] = (X['PoolArea'] > 0).astype(int)\n",
    "        X['TotalPorchSF'] = X['OpenPorchSF'] + X['EnclosedPorch'] + X['3SsnPorch'] + X['ScreenPorch']\n",
    "        X['OverallHouseCondition'] = X['OverallQual'] * X['OverallCond']\n",
    "        \n",
    "        # Create interaction features\n",
    "        X['TotalSF_OverallQual'] = X['TotalSF'] * X['OverallQual']\n",
    "        X['GrLivArea_TotRmsAbvGrd'] = X['GrLivArea'] * X['TotRmsAbvGrd']\n",
    "        X['HouseAge_OverallQual'] = X['HouseAge'] * X['OverallQual']\n",
    "        X['GarageArea_GarageCars'] = X['GarageArea'] * X['GarageCars']\n",
    "        X['YearBuilt_YearRemodAdd'] = X['YearBuilt'] * X['YearRemodAdd']\n",
    "        X['TotalSF_HouseAge'] = X['TotalSF'] * X['HouseAge']\n",
    "        X['1stFlrSF_2ndFlrSF'] = X['1stFlrSF'] * X['2ndFlrSF']\n",
    "        X['TotalSF_OverallCond'] = X['TotalSF'] * X['OverallCond']\n",
    "        \n",
    "        # Interaction with categorical variable (requires encoding)\n",
    "        X['GrLivArea_Neighborhood'] = X['GrLivArea'] * pd.factorize(X['Neighborhood'])[0]\n",
    "        \n",
    "        return X\n",
    "\n",
    "def pandas_to_numpy(X):\n",
    "    return X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "def preprocess_and_engineer(X):\n",
    "    # Apply FeatureEngineer first\n",
    "    feature_engineer = FeatureEngineer()\n",
    "    X_engineered = feature_engineer.fit_transform(X.copy())\n",
    "    \n",
    "    # Identify numeric, categorical, and year columns\n",
    "    numeric_features = X_engineered.select_dtypes(include=['int64', 'float64']).columns.drop(['YearBuilt', 'YearRemodAdd', 'YrSold'])\n",
    "    categorical_features = X_engineered.select_dtypes(include=['object']).columns\n",
    "    year_features = ['YearBuilt', 'YearRemodAdd', 'YrSold']\n",
    "    \n",
    "    print(\"Number of features before preprocessing:\")\n",
    "    print(f\"Numeric: {len(numeric_features)}\")\n",
    "    print(f\"Categorical: {len(categorical_features)}\")\n",
    "    print(f\"Year: {len(year_features)}\")\n",
    "    \n",
    "    # Create preprocessing steps\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('outlier_capper', OutlierCapper()),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore', max_categories=10)),\n",
    "    ])\n",
    "\n",
    "    year_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('converter', YearConverter()),\n",
    "    ])\n",
    "\n",
    "    # Create and fit the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('year', year_transformer, year_features)\n",
    "        ])\n",
    "    \n",
    "    X_preprocessed = preprocessor.fit_transform(X_engineered)\n",
    "    \n",
    "    # Generate feature names\n",
    "    numeric_feature_names = list(numeric_features)\n",
    "    categorical_feature_names = []\n",
    "    onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    \n",
    "    print(\"\\nCategorical feature encoding details:\")\n",
    "    for i, feature in enumerate(categorical_features):\n",
    "        categories = onehot_encoder.categories_[i]\n",
    "        n_categories = min(len(categories), 10)  # Account for max_categories=10\n",
    "        n_encoded = n_categories - 1  # Subtract 1 due to drop='first'\n",
    "        print(f\"{feature}: {n_categories} categories, {n_encoded} encoded features\")\n",
    "        categorical_feature_names.extend([f\"{feature}_{cat}\" for cat in categories[1:n_categories]])\n",
    "    \n",
    "    year_feature_names = list(year_features)\n",
    "    \n",
    "    feature_names = (numeric_feature_names + \n",
    "                     categorical_feature_names + \n",
    "                     year_feature_names)\n",
    "    \n",
    "    print(\"\\nNumber of features after preprocessing:\")\n",
    "    print(f\"Numeric: {len(numeric_feature_names)}\")\n",
    "    print(f\"Categorical (one-hot encoded): {len(categorical_feature_names)}\")\n",
    "    print(f\"Year: {len(year_feature_names)}\")\n",
    "    \n",
    "    print(f\"\\nTotal number of features: {len(feature_names)}\")\n",
    "    print(f\"Number of columns in preprocessed data: {X_preprocessed.shape[1]}\")\n",
    "    \n",
    "    # Ensure the number of feature names matches the number of columns in X_preprocessed\n",
    "    if len(feature_names) != X_preprocessed.shape[1]:\n",
    "        print(f\"\\nWarning: Number of feature names ({len(feature_names)}) \"\n",
    "              f\"does not match number of columns in preprocessed data ({X_preprocessed.shape[1]})\")\n",
    "        print(\"Adjusting feature names...\")\n",
    "        if len(feature_names) > X_preprocessed.shape[1]:\n",
    "            feature_names = feature_names[:X_preprocessed.shape[1]]\n",
    "        else:\n",
    "            feature_names += [f'Unknown_{i}' for i in range(X_preprocessed.shape[1] - len(feature_names))]\n",
    "    \n",
    "    # Store feature names as an attribute of the DataFrame\n",
    "    df = pd.DataFrame(X_preprocessed, columns=feature_names, index=X.index)\n",
    "    df.attrs['feature_names'] = feature_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/Users/ttanaka/Desktop/Website/house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Full pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocess_and_engineer', FunctionTransformer(preprocess_and_engineer, validate=False)),\n",
    "    ('to_numpy', FunctionTransformer(pandas_to_numpy))\n",
    "])\n",
    "\n",
    "# Apply the pipeline\n",
    "X_processed = full_pipeline.fit_transform(X)\n",
    "\n",
    "# Validation\n",
    "print(\"\\nFinal validation:\")\n",
    "print(\"Shape after preprocessing:\", X_processed.shape)\n",
    "print(\"Missing values after preprocessing:\", np.isnan(X_processed).sum())\n",
    "\n",
    "# Split the processed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Access feature names from the intermediate DataFrame\n",
    "intermediate_df = full_pipeline.named_steps['preprocess_and_engineer'].transform(X)\n",
    "feature_names = intermediate_df.attrs.get('feature_names', [])\n",
    "print(\"Number of features:\", len(feature_names))\n",
    "print(\"First 10 feature names:\", feature_names[:10])\n",
    "print(\"Last 10 feature names:\", feature_names[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "522e8367-1bd1-49ca-99f9-4e5ddfc686c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "MAE: 17577.4 (±2388.1)\n",
      "MSE: 936744142.0 (±550308478.5)\n",
      "RMSE: 30606.3 (±23458.7)\n",
      "MAPE: 10.14% (±1.06%)\n",
      "MedAE: 10972.8 (±1882.2)\n",
      "R²: 0.851 (±0.072)\n",
      "\n",
      "Gradient Boosting:\n",
      "MAE: 16361.4 (±1846.1)\n",
      "MSE: 841185633.4 (±453050944.9)\n",
      "RMSE: 29003.2 (±21285.0)\n",
      "MAPE: 9.43% (±1.08%)\n",
      "MedAE: 10081.1 (±1158.8)\n",
      "R²: 0.868 (±0.052)\n",
      "\n",
      "SVM (tuned):\n",
      "MAE: 16190.0 (±2751.3)\n",
      "MSE: 854546628.4 (±613610477.2)\n",
      "RMSE: 29232.6 (±24771.2)\n",
      "MAPE: 9.43% (±1.09%)\n",
      "MedAE: 10484.0 (±1913.6)\n",
      "R²: 0.867 (±0.071)\n",
      "\n",
      "Elastic Net:\n",
      "MAE: 17998.6 (±2671.6)\n",
      "MSE: 971907418.5 (±643087728.2)\n",
      "RMSE: 31175.4 (±25359.2)\n",
      "MAPE: 10.24% (±1.07%)\n",
      "MedAE: 12387.4 (±1903.4)\n",
      "R²: 0.848 (±0.073)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+10, tolerance: 7.592e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e+10, tolerance: 7.288e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+09, tolerance: 6.990e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+11, tolerance: 7.249e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+10, tolerance: 7.592e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e+10, tolerance: 7.288e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+09, tolerance: 6.990e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+11, tolerance: 7.249e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+10, tolerance: 7.592e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e+10, tolerance: 7.288e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+09, tolerance: 6.990e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+11, tolerance: 7.249e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+10, tolerance: 7.592e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e+10, tolerance: 7.288e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+09, tolerance: 6.990e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+11, tolerance: 7.249e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+10, tolerance: 7.592e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e+10, tolerance: 7.288e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+09, tolerance: 6.990e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ttanaka/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+11, tolerance: 7.249e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking:\n",
      "MAE: 15816.4 (±2518.0)\n",
      "MSE: 796930261.8 (±597972816.7)\n",
      "RMSE: 28230.0 (±24453.5)\n",
      "MAPE: 9.31% (±1.10%)\n",
      "MedAE: 10275.4 (±1337.1)\n",
      "R²: 0.876 (±0.073)\n",
      "\n",
      "Voting:\n",
      "MAE: 15576.9 (±2252.3)\n",
      "MSE: 795293683.3 (±525911764.7)\n",
      "RMSE: 28201.0 (±22932.8)\n",
      "MAPE: 8.91% (±0.97%)\n",
      "MedAE: 10029.2 (±1607.8)\n",
      "R²: 0.876 (±0.061)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "# Define models\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "svm = SVR(kernel='linear', C=834.2988013047346, epsilon=0.7722447692966574, gamma=0.0006235377135673155)\n",
    "en = ElasticNet(random_state=42)\n",
    "\n",
    "estimators = [\n",
    "    ('rf', rf),\n",
    "    ('gb', gb),\n",
    "    ('svm', svm),\n",
    "    ('en', en)\n",
    "]\n",
    "\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=ElasticNet(random_state=42)\n",
    ")\n",
    "\n",
    "voting_regressor = VotingRegressor(estimators=estimators)\n",
    "\n",
    "models = [rf, gb, svm, en, stacking_regressor, voting_regressor]\n",
    "model_names = ['Random Forest', 'Gradient Boosting', 'SVM (tuned)', 'Elastic Net', 'Stacking', 'Voting']\n",
    "\n",
    "\n",
    "# Perform cross-validation and calculate metrics\n",
    "for name, model in zip(model_names, models):\n",
    "    mae_scores = -cross_val_score(model, X_processed, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "    mse_scores = -cross_val_score(model, X_processed, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    r2_scores = cross_val_score(model, X_processed, y, scoring='r2', cv=5)\n",
    "    \n",
    "    # Calculate MAPE and MedAE using custom scorers\n",
    "    def mape_scorer(estimator, X, y):\n",
    "        y_pred = estimator.predict(X)\n",
    "        return np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "    def medae_scorer(estimator, X, y):\n",
    "        y_pred = estimator.predict(X)\n",
    "        return median_absolute_error(y, y_pred)\n",
    "\n",
    "    mape_scores = cross_val_score(model, X_processed, y, scoring=mape_scorer, cv=5)\n",
    "    medae_scores = cross_val_score(model, X_processed, y, scoring=medae_scorer, cv=5)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"MAE: {mae_scores.mean():.1f} (±{mae_scores.std() * 2:.1f})\")\n",
    "    print(f\"MSE: {mse_scores.mean():.1f} (±{mse_scores.std() * 2:.1f})\")\n",
    "    print(f\"RMSE: {np.sqrt(mse_scores.mean()):.1f} (±{np.sqrt(mse_scores.std() * 2):.1f})\")\n",
    "    print(f\"MAPE: {mape_scores.mean():.2f}% (±{mape_scores.std() * 2:.2f}%)\")\n",
    "    print(f\"MedAE: {medae_scores.mean():.1f} (±{medae_scores.std() * 2:.1f})\")\n",
    "    print(f\"R²: {r2_scores.mean():.3f} (±{r2_scores.std() * 2:.3f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08f016-85cb-44bc-b0fe-b47315379ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
