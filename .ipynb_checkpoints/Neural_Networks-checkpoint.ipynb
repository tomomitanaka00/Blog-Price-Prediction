{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa1ec5e-ad24-43c4-96b7-24fc18ca918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before preprocessing:\n",
      "Numeric: 51\n",
      "Categorical: 43\n",
      "Year: 3\n",
      "\n",
      "Categorical feature encoding details:\n",
      "MSZoning: 5 categories, 4 encoded features\n",
      "Street: 2 categories, 1 encoded features\n",
      "Alley: 3 categories, 2 encoded features\n",
      "LotShape: 4 categories, 3 encoded features\n",
      "LandContour: 4 categories, 3 encoded features\n",
      "Utilities: 2 categories, 1 encoded features\n",
      "LotConfig: 5 categories, 4 encoded features\n",
      "LandSlope: 3 categories, 2 encoded features\n",
      "Neighborhood: 10 categories, 9 encoded features\n",
      "Condition1: 9 categories, 8 encoded features\n",
      "Condition2: 8 categories, 7 encoded features\n",
      "BldgType: 5 categories, 4 encoded features\n",
      "HouseStyle: 8 categories, 7 encoded features\n",
      "RoofStyle: 6 categories, 5 encoded features\n",
      "RoofMatl: 8 categories, 7 encoded features\n",
      "Exterior1st: 10 categories, 9 encoded features\n",
      "Exterior2nd: 10 categories, 9 encoded features\n",
      "MasVnrType: 4 categories, 3 encoded features\n",
      "ExterQual: 4 categories, 3 encoded features\n",
      "ExterCond: 5 categories, 4 encoded features\n",
      "Foundation: 6 categories, 5 encoded features\n",
      "BsmtQual: 5 categories, 4 encoded features\n",
      "BsmtCond: 5 categories, 4 encoded features\n",
      "BsmtExposure: 5 categories, 4 encoded features\n",
      "BsmtFinType1: 7 categories, 6 encoded features\n",
      "BsmtFinType2: 7 categories, 6 encoded features\n",
      "Heating: 6 categories, 5 encoded features\n",
      "HeatingQC: 5 categories, 4 encoded features\n",
      "CentralAir: 2 categories, 1 encoded features\n",
      "Electrical: 6 categories, 5 encoded features\n",
      "KitchenQual: 4 categories, 3 encoded features\n",
      "Functional: 7 categories, 6 encoded features\n",
      "FireplaceQu: 6 categories, 5 encoded features\n",
      "GarageType: 7 categories, 6 encoded features\n",
      "GarageFinish: 4 categories, 3 encoded features\n",
      "GarageQual: 6 categories, 5 encoded features\n",
      "GarageCond: 6 categories, 5 encoded features\n",
      "PavedDrive: 3 categories, 2 encoded features\n",
      "PoolQC: 4 categories, 3 encoded features\n",
      "Fence: 5 categories, 4 encoded features\n",
      "MiscFeature: 5 categories, 4 encoded features\n",
      "SaleType: 9 categories, 8 encoded features\n",
      "SaleCondition: 6 categories, 5 encoded features\n",
      "\n",
      "Number of features after preprocessing:\n",
      "Numeric: 51\n",
      "Categorical (one-hot encoded): 198\n",
      "Year: 3\n",
      "\n",
      "Total number of features: 252\n",
      "Number of columns in preprocessed data: 252\n",
      "\n",
      "Final validation:\n",
      "Shape after preprocessing: (1460, 252)\n",
      "Missing values after preprocessing: 0\n",
      "Number of features before preprocessing:\n",
      "Numeric: 51\n",
      "Categorical: 43\n",
      "Year: 3\n",
      "\n",
      "Categorical feature encoding details:\n",
      "MSZoning: 5 categories, 4 encoded features\n",
      "Street: 2 categories, 1 encoded features\n",
      "Alley: 3 categories, 2 encoded features\n",
      "LotShape: 4 categories, 3 encoded features\n",
      "LandContour: 4 categories, 3 encoded features\n",
      "Utilities: 2 categories, 1 encoded features\n",
      "LotConfig: 5 categories, 4 encoded features\n",
      "LandSlope: 3 categories, 2 encoded features\n",
      "Neighborhood: 10 categories, 9 encoded features\n",
      "Condition1: 9 categories, 8 encoded features\n",
      "Condition2: 8 categories, 7 encoded features\n",
      "BldgType: 5 categories, 4 encoded features\n",
      "HouseStyle: 8 categories, 7 encoded features\n",
      "RoofStyle: 6 categories, 5 encoded features\n",
      "RoofMatl: 8 categories, 7 encoded features\n",
      "Exterior1st: 10 categories, 9 encoded features\n",
      "Exterior2nd: 10 categories, 9 encoded features\n",
      "MasVnrType: 4 categories, 3 encoded features\n",
      "ExterQual: 4 categories, 3 encoded features\n",
      "ExterCond: 5 categories, 4 encoded features\n",
      "Foundation: 6 categories, 5 encoded features\n",
      "BsmtQual: 5 categories, 4 encoded features\n",
      "BsmtCond: 5 categories, 4 encoded features\n",
      "BsmtExposure: 5 categories, 4 encoded features\n",
      "BsmtFinType1: 7 categories, 6 encoded features\n",
      "BsmtFinType2: 7 categories, 6 encoded features\n",
      "Heating: 6 categories, 5 encoded features\n",
      "HeatingQC: 5 categories, 4 encoded features\n",
      "CentralAir: 2 categories, 1 encoded features\n",
      "Electrical: 6 categories, 5 encoded features\n",
      "KitchenQual: 4 categories, 3 encoded features\n",
      "Functional: 7 categories, 6 encoded features\n",
      "FireplaceQu: 6 categories, 5 encoded features\n",
      "GarageType: 7 categories, 6 encoded features\n",
      "GarageFinish: 4 categories, 3 encoded features\n",
      "GarageQual: 6 categories, 5 encoded features\n",
      "GarageCond: 6 categories, 5 encoded features\n",
      "PavedDrive: 3 categories, 2 encoded features\n",
      "PoolQC: 4 categories, 3 encoded features\n",
      "Fence: 5 categories, 4 encoded features\n",
      "MiscFeature: 5 categories, 4 encoded features\n",
      "SaleType: 9 categories, 8 encoded features\n",
      "SaleCondition: 6 categories, 5 encoded features\n",
      "\n",
      "Number of features after preprocessing:\n",
      "Numeric: 51\n",
      "Categorical (one-hot encoded): 198\n",
      "Year: 3\n",
      "\n",
      "Total number of features: 252\n",
      "Number of columns in preprocessed data: 252\n",
      "Number of features: 252\n",
      "First 10 feature names: ['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF']\n",
      "Last 10 feature names: ['SaleType_Oth', 'SaleType_WD', 'SaleCondition_AdjLand', 'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal', 'SaleCondition_Partial', 'YearBuilt', 'YearRemodAdd', 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and engineering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Removed: import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "\n",
    "class OutlierCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "        self.lower_bounds = None\n",
    "        self.upper_bounds = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.lower_bounds = np.quantile(X, self.lower_quantile, axis=0)\n",
    "        self.upper_bounds = np.quantile(X, self.upper_quantile, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.clip(X, self.lower_bounds, self.upper_bounds)\n",
    "\n",
    "class YearConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.min_year = None\n",
    "        self.max_year = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_flat = X.ravel() if X.ndim > 1 else X\n",
    "        self.min_year = np.min(X_flat)\n",
    "        self.max_year = min(np.max(X_flat), pd.Timestamp.now().year)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_numeric = pd.to_numeric(X.ravel() if X.ndim > 1 else X, errors='coerce')\n",
    "        X_clipped = np.clip(X_numeric, self.min_year, self.max_year)\n",
    "        return X_clipped.reshape(X.shape)\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Create new features\n",
    "        X['TotalSF'] = X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']\n",
    "        \n",
    "        current_year = pd.Timestamp.now().year\n",
    "        X['HouseAge'] = current_year - X['YearBuilt']\n",
    "        X['TimeSinceRemodel'] = current_year - X['YearRemodAdd']\n",
    "        \n",
    "        X['TotalBathrooms'] = X['FullBath'] + (0.5 * X['HalfBath']) + X['BsmtFullBath'] + (0.5 * X['BsmtHalfBath'])\n",
    "        X['IsNewHouse'] = (X['YearBuilt'] == X['YrSold']).astype(int)\n",
    "        X['HasPool'] = (X['PoolArea'] > 0).astype(int)\n",
    "        X['TotalPorchSF'] = X['OpenPorchSF'] + X['EnclosedPorch'] + X['3SsnPorch'] + X['ScreenPorch']\n",
    "        X['OverallHouseCondition'] = X['OverallQual'] * X['OverallCond']\n",
    "        \n",
    "        # Create interaction features\n",
    "        X['TotalSF_OverallQual'] = X['TotalSF'] * X['OverallQual']\n",
    "        X['GrLivArea_TotRmsAbvGrd'] = X['GrLivArea'] * X['TotRmsAbvGrd']\n",
    "        X['HouseAge_OverallQual'] = X['HouseAge'] * X['OverallQual']\n",
    "        X['GarageArea_GarageCars'] = X['GarageArea'] * X['GarageCars']\n",
    "        X['YearBuilt_YearRemodAdd'] = X['YearBuilt'] * X['YearRemodAdd']\n",
    "        X['TotalSF_HouseAge'] = X['TotalSF'] * X['HouseAge']\n",
    "        X['1stFlrSF_2ndFlrSF'] = X['1stFlrSF'] * X['2ndFlrSF']\n",
    "        X['TotalSF_OverallCond'] = X['TotalSF'] * X['OverallCond']\n",
    "        \n",
    "        # Interaction with categorical variable (requires encoding)\n",
    "        X['GrLivArea_Neighborhood'] = X['GrLivArea'] * pd.factorize(X['Neighborhood'])[0]\n",
    "        \n",
    "        return X\n",
    "\n",
    "def pandas_to_numpy(X):\n",
    "    return X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "def preprocess_and_engineer(X):\n",
    "    # Apply FeatureEngineer first\n",
    "    feature_engineer = FeatureEngineer()\n",
    "    X_engineered = feature_engineer.fit_transform(X.copy())\n",
    "    \n",
    "    # Identify numeric, categorical, and year columns\n",
    "    numeric_features = X_engineered.select_dtypes(include=['int64', 'float64']).columns.drop(['YearBuilt', 'YearRemodAdd', 'YrSold'])\n",
    "    categorical_features = X_engineered.select_dtypes(include=['object']).columns\n",
    "    year_features = ['YearBuilt', 'YearRemodAdd', 'YrSold']\n",
    "    \n",
    "    print(\"Number of features before preprocessing:\")\n",
    "    print(f\"Numeric: {len(numeric_features)}\")\n",
    "    print(f\"Categorical: {len(categorical_features)}\")\n",
    "    print(f\"Year: {len(year_features)}\")\n",
    "    \n",
    "    # Create preprocessing steps\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('outlier_capper', OutlierCapper()),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore', max_categories=10)),\n",
    "    ])\n",
    "\n",
    "    year_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('converter', YearConverter()),\n",
    "    ])\n",
    "\n",
    "    # Create and fit the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('year', year_transformer, year_features)\n",
    "        ])\n",
    "    \n",
    "    X_preprocessed = preprocessor.fit_transform(X_engineered)\n",
    "    \n",
    "    # Generate feature names\n",
    "    numeric_feature_names = list(numeric_features)\n",
    "    categorical_feature_names = []\n",
    "    onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    \n",
    "    print(\"\\nCategorical feature encoding details:\")\n",
    "    for i, feature in enumerate(categorical_features):\n",
    "        categories = onehot_encoder.categories_[i]\n",
    "        n_categories = min(len(categories), 10)  # Account for max_categories=10\n",
    "        n_encoded = n_categories - 1  # Subtract 1 due to drop='first'\n",
    "        print(f\"{feature}: {n_categories} categories, {n_encoded} encoded features\")\n",
    "        categorical_feature_names.extend([f\"{feature}_{cat}\" for cat in categories[1:n_categories]])\n",
    "    \n",
    "    year_feature_names = list(year_features)\n",
    "    \n",
    "    feature_names = (numeric_feature_names + \n",
    "                     categorical_feature_names + \n",
    "                     year_feature_names)\n",
    "    \n",
    "    print(\"\\nNumber of features after preprocessing:\")\n",
    "    print(f\"Numeric: {len(numeric_feature_names)}\")\n",
    "    print(f\"Categorical (one-hot encoded): {len(categorical_feature_names)}\")\n",
    "    print(f\"Year: {len(year_feature_names)}\")\n",
    "    \n",
    "    print(f\"\\nTotal number of features: {len(feature_names)}\")\n",
    "    print(f\"Number of columns in preprocessed data: {X_preprocessed.shape[1]}\")\n",
    "    \n",
    "    # Ensure the number of feature names matches the number of columns in X_preprocessed\n",
    "    if len(feature_names) != X_preprocessed.shape[1]:\n",
    "        print(f\"\\nWarning: Number of feature names ({len(feature_names)}) \"\n",
    "              f\"does not match number of columns in preprocessed data ({X_preprocessed.shape[1]})\")\n",
    "        print(\"Adjusting feature names...\")\n",
    "        if len(feature_names) > X_preprocessed.shape[1]:\n",
    "            feature_names = feature_names[:X_preprocessed.shape[1]]\n",
    "        else:\n",
    "            feature_names += [f'Unknown_{i}' for i in range(X_preprocessed.shape[1] - len(feature_names))]\n",
    "    \n",
    "    # Store feature names as an attribute of the DataFrame\n",
    "    df = pd.DataFrame(X_preprocessed, columns=feature_names, index=X.index)\n",
    "    df.attrs['feature_names'] = feature_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/Users/ttanaka/Desktop/Website/house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Full pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocess_and_engineer', FunctionTransformer(preprocess_and_engineer, validate=False)),\n",
    "    ('to_numpy', FunctionTransformer(pandas_to_numpy))\n",
    "])\n",
    "\n",
    "# Apply the pipeline\n",
    "X_processed = full_pipeline.fit_transform(X)\n",
    "\n",
    "# Validation\n",
    "print(\"\\nFinal validation:\")\n",
    "print(\"Shape after preprocessing:\", X_processed.shape)\n",
    "print(\"Missing values after preprocessing:\", np.isnan(X_processed).sum())\n",
    "\n",
    "# Split the processed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Access feature names from the intermediate DataFrame\n",
    "intermediate_df = full_pipeline.named_steps['preprocess_and_engineer'].transform(X)\n",
    "feature_names = intermediate_df.attrs.get('feature_names', [])\n",
    "print(\"Number of features:\", len(feature_names))\n",
    "print(\"First 10 feature names:\", feature_names[:10])\n",
    "print(\"Last 10 feature names:\", feature_names[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e8367-1bd1-49ca-99f9-4e5ddfc686c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def medae(y_true, y_pred):\n",
    "    return median_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Create the model\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(64, 32, 16), \n",
    "                        activation='relu', \n",
    "                        solver='adam', \n",
    "                        alpha=0.0001,\n",
    "                        batch_size=32, \n",
    "                        learning_rate_init=0.001,\n",
    "                        max_iter=1000,\n",
    "                        random_state=42)\n",
    "\n",
    "# Prepare cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each metric\n",
    "mae_scores = cross_val_score(nn_model, X_processed, y, cv=cv, scoring='neg_mean_absolute_error')\n",
    "mse_scores = cross_val_score(nn_model, X_processed, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "r2_scores = cross_val_score(nn_model, X_processed, y, cv=cv, scoring='r2')\n",
    "medae_scores = cross_val_score(nn_model, X_processed, y, cv=cv, scoring=make_scorer(medae))\n",
    "mape_scores = cross_val_score(nn_model, X_processed, y, cv=cv, scoring=make_scorer(mape))\n",
    "\n",
    "# Calculate mean and standard error for each metric\n",
    "mae_mean, mae_se = -mae_scores.mean(), mae_scores.std() / np.sqrt(cv.n_splits)\n",
    "mse_mean, mse_se = -mse_scores.mean(), mse_scores.std() / np.sqrt(cv.n_splits)\n",
    "rmse_mean, rmse_se = np.sqrt(-mse_scores).mean(), np.sqrt(-mse_scores).std() / np.sqrt(cv.n_splits)\n",
    "r2_mean, r2_se = r2_scores.mean(), r2_scores.std() / np.sqrt(cv.n_splits)\n",
    "medae_mean, medae_se = medae_scores.mean(), medae_scores.std() / np.sqrt(cv.n_splits)\n",
    "mape_mean, mape_se = mape_scores.mean(), mape_scores.std() / np.sqrt(cv.n_splits)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Absolute Error: {mae_mean:.2f} (±{mae_se:.2f})\")\n",
    "print(f\"Mean Squared Error: {mse_mean:.2f} (±{mse_se:.2f})\")\n",
    "print(f\"Root Mean Squared Error: {rmse_mean:.2f} (±{rmse_se:.2f})\")\n",
    "print(f\"Median Absolute Error: {medae_mean:.2f} (±{medae_se:.2f})\")\n",
    "print(f\"Mean Absolute Percentage Error: {mape_mean:.2f}% (±{mape_se:.2f}%)\")\n",
    "print(f\"R-squared Score: {r2_mean:.4f} (±{r2_se:.4f})\")\n",
    "\n",
    "# Train the model on the full dataset for feature importance\n",
    "nn_model.fit(X_processed, y)\n",
    "\n",
    "# Visualize the training process\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(nn_model.loss_curve_)\n",
    "plt.title('Neural Network Training Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = np.abs(nn_model.coefs_[0])\n",
    "feature_importance = feature_importance.sum(axis=1)\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.sum())\n",
    "\n",
    "features_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "features_df = features_df.sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='importance', y='feature', data=features_df)\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20364abf-ef35-49e3-9afa-7269ffd3b806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb236a-48e5-46b0-b9c2-add6875b9deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
