{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "686b50c6-f383-419e-805d-2c80620e37ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib successfully imported.\n",
      "Seaborn successfully imported.\n",
      "Scikit-learn modules successfully imported.\n",
      "All necessary libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"Matplotlib successfully imported.\")\n",
    "except ImportError:\n",
    "    print(\"Matplotlib not found. Please install it using: conda install matplotlib\")\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    print(\"Seaborn successfully imported.\")\n",
    "except ImportError:\n",
    "    print(\"Seaborn not found. Please install it using: conda install seaborn\")\n",
    "\n",
    "try:\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "    from sklearn.impute import KNNImputer, SimpleImputer\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    print(\"Scikit-learn modules successfully imported.\")\n",
    "except ImportError:\n",
    "    print(\"Scikit-learn not found or incomplete. Please install it using: conda install scikit-learn\")\n",
    "\n",
    "print(\"All necessary libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df37fbf7-adc9-4916-a571-d51e28f05290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME imported successfully\n",
      "\n",
      "LIME explanation for the first instance:\n",
      "0.49 < E <= 0.76: -0.0617\n",
      "0.51 < A <= 0.76: -0.0481\n",
      "C <= 0.26: -0.0359\n",
      "B <= 0.23: 0.0297\n",
      "0.23 < D <= 0.48: -0.0062\n",
      "LIME analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular\n",
    "    print(\"LIME imported successfully\")\n",
    "    \n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train.values, \n",
    "        feature_names=X.columns, \n",
    "        mode=\"regression\"\n",
    "    )\n",
    "    exp = explainer.explain_instance(X_test.iloc[0], rf_model.predict)\n",
    "    print(\"\\nLIME explanation for the first instance:\")\n",
    "    for feature, value in exp.as_list():\n",
    "        print(f\"{feature}: {value:.4f}\")\n",
    "    print(\"LIME analysis completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in LIME analysis: {str(e)}\")\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1eb27f1-b16f-4ce4-99d9-12004136ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before preprocessing:\n",
      "Numeric: 51\n",
      "Categorical: 43\n",
      "Year: 3\n",
      "\n",
      "Categorical feature encoding details:\n",
      "MSZoning: 5 categories, 4 encoded features\n",
      "Street: 2 categories, 1 encoded features\n",
      "Alley: 3 categories, 2 encoded features\n",
      "LotShape: 4 categories, 3 encoded features\n",
      "LandContour: 4 categories, 3 encoded features\n",
      "Utilities: 2 categories, 1 encoded features\n",
      "LotConfig: 5 categories, 4 encoded features\n",
      "LandSlope: 3 categories, 2 encoded features\n",
      "Neighborhood: 10 categories, 9 encoded features\n",
      "Condition1: 9 categories, 8 encoded features\n",
      "Condition2: 8 categories, 7 encoded features\n",
      "BldgType: 5 categories, 4 encoded features\n",
      "HouseStyle: 8 categories, 7 encoded features\n",
      "RoofStyle: 6 categories, 5 encoded features\n",
      "RoofMatl: 8 categories, 7 encoded features\n",
      "Exterior1st: 10 categories, 9 encoded features\n",
      "Exterior2nd: 10 categories, 9 encoded features\n",
      "MasVnrType: 4 categories, 3 encoded features\n",
      "ExterQual: 4 categories, 3 encoded features\n",
      "ExterCond: 5 categories, 4 encoded features\n",
      "Foundation: 6 categories, 5 encoded features\n",
      "BsmtQual: 5 categories, 4 encoded features\n",
      "BsmtCond: 5 categories, 4 encoded features\n",
      "BsmtExposure: 5 categories, 4 encoded features\n",
      "BsmtFinType1: 7 categories, 6 encoded features\n",
      "BsmtFinType2: 7 categories, 6 encoded features\n",
      "Heating: 6 categories, 5 encoded features\n",
      "HeatingQC: 5 categories, 4 encoded features\n",
      "CentralAir: 2 categories, 1 encoded features\n",
      "Electrical: 6 categories, 5 encoded features\n",
      "KitchenQual: 4 categories, 3 encoded features\n",
      "Functional: 7 categories, 6 encoded features\n",
      "FireplaceQu: 6 categories, 5 encoded features\n",
      "GarageType: 7 categories, 6 encoded features\n",
      "GarageFinish: 4 categories, 3 encoded features\n",
      "GarageQual: 6 categories, 5 encoded features\n",
      "GarageCond: 6 categories, 5 encoded features\n",
      "PavedDrive: 3 categories, 2 encoded features\n",
      "PoolQC: 4 categories, 3 encoded features\n",
      "Fence: 5 categories, 4 encoded features\n",
      "MiscFeature: 5 categories, 4 encoded features\n",
      "SaleType: 9 categories, 8 encoded features\n",
      "SaleCondition: 6 categories, 5 encoded features\n",
      "\n",
      "Number of features after preprocessing:\n",
      "Numeric: 51\n",
      "Categorical (one-hot encoded): 198\n",
      "Year: 3\n",
      "\n",
      "Total number of features: 252\n",
      "Number of columns in preprocessed data: 252\n",
      "\n",
      "Final validation:\n",
      "Shape after preprocessing: (1460, 252)\n",
      "Missing values after preprocessing: 0\n",
      "Number of features before preprocessing:\n",
      "Numeric: 51\n",
      "Categorical: 43\n",
      "Year: 3\n",
      "\n",
      "Categorical feature encoding details:\n",
      "MSZoning: 5 categories, 4 encoded features\n",
      "Street: 2 categories, 1 encoded features\n",
      "Alley: 3 categories, 2 encoded features\n",
      "LotShape: 4 categories, 3 encoded features\n",
      "LandContour: 4 categories, 3 encoded features\n",
      "Utilities: 2 categories, 1 encoded features\n",
      "LotConfig: 5 categories, 4 encoded features\n",
      "LandSlope: 3 categories, 2 encoded features\n",
      "Neighborhood: 10 categories, 9 encoded features\n",
      "Condition1: 9 categories, 8 encoded features\n",
      "Condition2: 8 categories, 7 encoded features\n",
      "BldgType: 5 categories, 4 encoded features\n",
      "HouseStyle: 8 categories, 7 encoded features\n",
      "RoofStyle: 6 categories, 5 encoded features\n",
      "RoofMatl: 8 categories, 7 encoded features\n",
      "Exterior1st: 10 categories, 9 encoded features\n",
      "Exterior2nd: 10 categories, 9 encoded features\n",
      "MasVnrType: 4 categories, 3 encoded features\n",
      "ExterQual: 4 categories, 3 encoded features\n",
      "ExterCond: 5 categories, 4 encoded features\n",
      "Foundation: 6 categories, 5 encoded features\n",
      "BsmtQual: 5 categories, 4 encoded features\n",
      "BsmtCond: 5 categories, 4 encoded features\n",
      "BsmtExposure: 5 categories, 4 encoded features\n",
      "BsmtFinType1: 7 categories, 6 encoded features\n",
      "BsmtFinType2: 7 categories, 6 encoded features\n",
      "Heating: 6 categories, 5 encoded features\n",
      "HeatingQC: 5 categories, 4 encoded features\n",
      "CentralAir: 2 categories, 1 encoded features\n",
      "Electrical: 6 categories, 5 encoded features\n",
      "KitchenQual: 4 categories, 3 encoded features\n",
      "Functional: 7 categories, 6 encoded features\n",
      "FireplaceQu: 6 categories, 5 encoded features\n",
      "GarageType: 7 categories, 6 encoded features\n",
      "GarageFinish: 4 categories, 3 encoded features\n",
      "GarageQual: 6 categories, 5 encoded features\n",
      "GarageCond: 6 categories, 5 encoded features\n",
      "PavedDrive: 3 categories, 2 encoded features\n",
      "PoolQC: 4 categories, 3 encoded features\n",
      "Fence: 5 categories, 4 encoded features\n",
      "MiscFeature: 5 categories, 4 encoded features\n",
      "SaleType: 9 categories, 8 encoded features\n",
      "SaleCondition: 6 categories, 5 encoded features\n",
      "\n",
      "Number of features after preprocessing:\n",
      "Numeric: 51\n",
      "Categorical (one-hot encoded): 198\n",
      "Year: 3\n",
      "\n",
      "Total number of features: 252\n",
      "Number of columns in preprocessed data: 252\n",
      "Number of features: 252\n",
      "First 10 feature names: ['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF']\n",
      "Last 10 feature names: ['SaleType_Oth', 'SaleType_WD', 'SaleCondition_AdjLand', 'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal', 'SaleCondition_Partial', 'YearBuilt', 'YearRemodAdd', 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and engineering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Removed: import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "\n",
    "class OutlierCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "        self.lower_bounds = None\n",
    "        self.upper_bounds = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.lower_bounds = np.quantile(X, self.lower_quantile, axis=0)\n",
    "        self.upper_bounds = np.quantile(X, self.upper_quantile, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.clip(X, self.lower_bounds, self.upper_bounds)\n",
    "\n",
    "class YearConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.min_year = None\n",
    "        self.max_year = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_flat = X.ravel() if X.ndim > 1 else X\n",
    "        self.min_year = np.min(X_flat)\n",
    "        self.max_year = min(np.max(X_flat), pd.Timestamp.now().year)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_numeric = pd.to_numeric(X.ravel() if X.ndim > 1 else X, errors='coerce')\n",
    "        X_clipped = np.clip(X_numeric, self.min_year, self.max_year)\n",
    "        return X_clipped.reshape(X.shape)\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Create new features\n",
    "        X['TotalSF'] = X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']\n",
    "        \n",
    "        current_year = pd.Timestamp.now().year\n",
    "        X['HouseAge'] = current_year - X['YearBuilt']\n",
    "        X['TimeSinceRemodel'] = current_year - X['YearRemodAdd']\n",
    "        \n",
    "        X['TotalBathrooms'] = X['FullBath'] + (0.5 * X['HalfBath']) + X['BsmtFullBath'] + (0.5 * X['BsmtHalfBath'])\n",
    "        X['IsNewHouse'] = (X['YearBuilt'] == X['YrSold']).astype(int)\n",
    "        X['HasPool'] = (X['PoolArea'] > 0).astype(int)\n",
    "        X['TotalPorchSF'] = X['OpenPorchSF'] + X['EnclosedPorch'] + X['3SsnPorch'] + X['ScreenPorch']\n",
    "        X['OverallHouseCondition'] = X['OverallQual'] * X['OverallCond']\n",
    "        \n",
    "        # Create interaction features\n",
    "        X['TotalSF_OverallQual'] = X['TotalSF'] * X['OverallQual']\n",
    "        X['GrLivArea_TotRmsAbvGrd'] = X['GrLivArea'] * X['TotRmsAbvGrd']\n",
    "        X['HouseAge_OverallQual'] = X['HouseAge'] * X['OverallQual']\n",
    "        X['GarageArea_GarageCars'] = X['GarageArea'] * X['GarageCars']\n",
    "        X['YearBuilt_YearRemodAdd'] = X['YearBuilt'] * X['YearRemodAdd']\n",
    "        X['TotalSF_HouseAge'] = X['TotalSF'] * X['HouseAge']\n",
    "        X['1stFlrSF_2ndFlrSF'] = X['1stFlrSF'] * X['2ndFlrSF']\n",
    "        X['TotalSF_OverallCond'] = X['TotalSF'] * X['OverallCond']\n",
    "        \n",
    "        # Interaction with categorical variable (requires encoding)\n",
    "        X['GrLivArea_Neighborhood'] = X['GrLivArea'] * pd.factorize(X['Neighborhood'])[0]\n",
    "        \n",
    "        return X\n",
    "\n",
    "def pandas_to_numpy(X):\n",
    "    return X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "def preprocess_and_engineer(X):\n",
    "    # Apply FeatureEngineer first\n",
    "    feature_engineer = FeatureEngineer()\n",
    "    X_engineered = feature_engineer.fit_transform(X.copy())\n",
    "    \n",
    "    # Identify numeric, categorical, and year columns\n",
    "    numeric_features = X_engineered.select_dtypes(include=['int64', 'float64']).columns.drop(['YearBuilt', 'YearRemodAdd', 'YrSold'])\n",
    "    categorical_features = X_engineered.select_dtypes(include=['object']).columns\n",
    "    year_features = ['YearBuilt', 'YearRemodAdd', 'YrSold']\n",
    "    \n",
    "    print(\"Number of features before preprocessing:\")\n",
    "    print(f\"Numeric: {len(numeric_features)}\")\n",
    "    print(f\"Categorical: {len(categorical_features)}\")\n",
    "    print(f\"Year: {len(year_features)}\")\n",
    "    \n",
    "    # Create preprocessing steps\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('outlier_capper', OutlierCapper()),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore', max_categories=10)),\n",
    "    ])\n",
    "\n",
    "    year_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('converter', YearConverter()),\n",
    "    ])\n",
    "\n",
    "    # Create and fit the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('year', year_transformer, year_features)\n",
    "        ])\n",
    "    \n",
    "    X_preprocessed = preprocessor.fit_transform(X_engineered)\n",
    "    \n",
    "    # Generate feature names\n",
    "    numeric_feature_names = list(numeric_features)\n",
    "    categorical_feature_names = []\n",
    "    onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    \n",
    "    print(\"\\nCategorical feature encoding details:\")\n",
    "    for i, feature in enumerate(categorical_features):\n",
    "        categories = onehot_encoder.categories_[i]\n",
    "        n_categories = min(len(categories), 10)  # Account for max_categories=10\n",
    "        n_encoded = n_categories - 1  # Subtract 1 due to drop='first'\n",
    "        print(f\"{feature}: {n_categories} categories, {n_encoded} encoded features\")\n",
    "        categorical_feature_names.extend([f\"{feature}_{cat}\" for cat in categories[1:n_categories]])\n",
    "    \n",
    "    year_feature_names = list(year_features)\n",
    "    \n",
    "    feature_names = (numeric_feature_names + \n",
    "                     categorical_feature_names + \n",
    "                     year_feature_names)\n",
    "    \n",
    "    print(\"\\nNumber of features after preprocessing:\")\n",
    "    print(f\"Numeric: {len(numeric_feature_names)}\")\n",
    "    print(f\"Categorical (one-hot encoded): {len(categorical_feature_names)}\")\n",
    "    print(f\"Year: {len(year_feature_names)}\")\n",
    "    \n",
    "    print(f\"\\nTotal number of features: {len(feature_names)}\")\n",
    "    print(f\"Number of columns in preprocessed data: {X_preprocessed.shape[1]}\")\n",
    "    \n",
    "    # Ensure the number of feature names matches the number of columns in X_preprocessed\n",
    "    if len(feature_names) != X_preprocessed.shape[1]:\n",
    "        print(f\"\\nWarning: Number of feature names ({len(feature_names)}) \"\n",
    "              f\"does not match number of columns in preprocessed data ({X_preprocessed.shape[1]})\")\n",
    "        print(\"Adjusting feature names...\")\n",
    "        if len(feature_names) > X_preprocessed.shape[1]:\n",
    "            feature_names = feature_names[:X_preprocessed.shape[1]]\n",
    "        else:\n",
    "            feature_names += [f'Unknown_{i}' for i in range(X_preprocessed.shape[1] - len(feature_names))]\n",
    "    \n",
    "    # Store feature names as an attribute of the DataFrame\n",
    "    df = pd.DataFrame(X_preprocessed, columns=feature_names, index=X.index)\n",
    "    df.attrs['feature_names'] = feature_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/Users/ttanaka/Desktop/Website/house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Full pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocess_and_engineer', FunctionTransformer(preprocess_and_engineer, validate=False)),\n",
    "    ('to_numpy', FunctionTransformer(pandas_to_numpy))\n",
    "])\n",
    "\n",
    "# Apply the pipeline\n",
    "X_processed = full_pipeline.fit_transform(X)\n",
    "\n",
    "# Validation\n",
    "print(\"\\nFinal validation:\")\n",
    "print(\"Shape after preprocessing:\", X_processed.shape)\n",
    "print(\"Missing values after preprocessing:\", np.isnan(X_processed).sum())\n",
    "\n",
    "# Split the processed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Access feature names from the intermediate DataFrame\n",
    "intermediate_df = full_pipeline.named_steps['preprocess_and_engineer'].transform(X)\n",
    "feature_names = intermediate_df.attrs.get('feature_names', [])\n",
    "print(\"Number of features:\", len(feature_names))\n",
    "print(\"First 10 feature names:\", feature_names[:10])\n",
    "print(\"Last 10 feature names:\", feature_names[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258673c2-78d0-442d-aa0a-f497198dcff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP version: 0.45.1\n",
      "\n",
      "SHAP values for the first instance:\n",
      "A: -0.0485\n",
      "B: 0.0105\n",
      "C: -0.0019\n",
      "D: -0.0155\n",
      "E: -0.0706\n",
      "SHAP analysis completed successfully!\n",
      "Error in LIME analysis: module 'lime' has no attribute '__version__'\n",
      "Error in ELI5 analysis: cannot import name 'if_delegate_has_method' from 'sklearn.utils.metaestimators' (/Users/ttanaka/miniconda3/envs/fresh_env/lib/python3.9/site-packages/sklearn/utils/metaestimators.py)\n",
      "\n",
      "InterpretML analysis:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d75eb3c50d44f9aa639e8cb855e55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterpretML SHAP values for the first 5 instances:\n",
      "Error in InterpretML analysis: 'NoneType' object is not subscriptable\n",
      "\n",
      "Installed packages:\n",
      "anyio==4.2.0\n",
      "appnope==0.1.2\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "asttokens==2.0.5\n",
      "async-lru==2.0.4\n",
      "attrs==23.1.0\n",
      "autocommand==2.2.2\n",
      "babel==2.11.0\n",
      "backcall==0.2.0\n",
      "backports.tarfile==1.2.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==4.1.0\n",
      "bottleneck==1.3.7\n",
      "brotli==1.0.9\n",
      "certifi==2024.7.4\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "cloudpickle==3.0.0\n",
      "colorama==0.4.6\n",
      "comm==0.2.1\n",
      "contourpy==1.2.1\n",
      "cycler==0.12.1\n",
      "debugpy==1.6.7\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "eli5==0.13.0\n",
      "exceptiongroup==1.2.0\n",
      "executing==0.8.3\n",
      "fastjsonschema==2.16.2\n",
      "fonttools==4.53.1\n",
      "graphviz==0.20.3\n",
      "idna==3.7\n",
      "imagecodecs==2023.1.23\n",
      "imageio==2.34.2\n",
      "importlib-metadata==7.0.1\n",
      "importlib-resources==6.4.2\n",
      "inflect==7.3.1\n",
      "ipykernel==6.28.0\n",
      "ipython==8.15.0\n",
      "ipywidgets==8.1.2\n",
      "jaraco.context==5.3.0\n",
      "jaraco.functools==4.0.1\n",
      "jaraco.text==3.12.1\n",
      "jedi==0.19.1\n",
      "jinja2==3.1.4\n",
      "joblib==1.4.2\n",
      "json5==0.9.6\n",
      "jsonschema==4.19.2\n",
      "jsonschema-specifications==2023.7.1\n",
      "jupyter==1.0.0\n",
      "jupyter-client==8.6.0\n",
      "jupyter-console==6.6.3\n",
      "jupyter-core==5.7.2\n",
      "jupyter-events==0.10.0\n",
      "jupyter-lsp==2.2.0\n",
      "jupyter-server==2.14.1\n",
      "jupyter-server-terminals==0.4.4\n",
      "jupyterlab==4.0.11\n",
      "jupyterlab-pygments==0.1.2\n",
      "jupyterlab-server==2.25.1\n",
      "jupyterlab-widgets==3.0.10\n",
      "kiwisolver==1.4.5\n",
      "lazy-loader==0.4\n",
      "lime==0.2.0.1\n",
      "llvmlite==0.43.0\n",
      "markupsafe==2.1.3\n",
      "matplotlib==3.9.2\n",
      "matplotlib-inline==0.1.6\n",
      "mistune==2.0.4\n",
      "more-itertools==10.3.0\n",
      "munkres==1.1.4\n",
      "nbclient==0.8.0\n",
      "nbconvert==7.10.0\n",
      "nbformat==5.9.2\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.2.1\n",
      "notebook==7.0.8\n",
      "notebook-shim==0.2.3\n",
      "numba==0.60.0\n",
      "numexpr==2.8.7\n",
      "numpy==1.23.5\n",
      "ordered-set==4.1.0\n",
      "overrides==7.4.0\n",
      "packaging==24.1\n",
      "pandas==2.2.2\n",
      "pandocfilters==1.5.0\n",
      "parso==0.8.3\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "pillow==9.4.0\n",
      "pip==24.2\n",
      "platformdirs==3.10.0\n",
      "ply==3.11\n",
      "prometheus-client==0.14.1\n",
      "prompt-toolkit==3.0.43\n",
      "psutil==5.9.0\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "pycparser==2.21\n",
      "pygments==2.15.1\n",
      "pyparsing==3.1.2\n",
      "pyqt5==5.15.10\n",
      "pyqt5-sip==12.13.0\n",
      "pysocks==1.7.1\n",
      "python-dateutil==2.9.0.post0\n",
      "python-json-logger==2.0.7\n",
      "pytz==2024.1\n",
      "pywavelets==1.6.0\n",
      "pyyaml==6.0.1\n",
      "pyzmq==25.1.2\n",
      "qtconsole==5.5.1\n",
      "qtpy==2.4.1\n",
      "referencing==0.30.2\n",
      "requests==2.32.3\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rpds-py==0.10.6\n",
      "scikit-image==0.24.0\n",
      "scikit-learn==1.5.1\n",
      "scipy==1.13.1\n",
      "send2trash==1.8.2\n",
      "setuptools==72.1.0\n",
      "shap==0.45.1\n",
      "singledispatch==0.0.0\n",
      "sip==6.7.12\n",
      "six==1.16.0\n",
      "slicer==0.0.8\n",
      "sniffio==1.3.0\n",
      "soupsieve==2.5\n",
      "stack-data==0.2.0\n",
      "tabulate==0.9.0\n",
      "terminado==0.17.1\n",
      "threadpoolctl==3.5.0\n",
      "tifffile==2023.8.12\n",
      "tinycss2==1.2.1\n",
      "tomli==2.0.1\n",
      "tornado==6.4.1\n",
      "tqdm==4.66.5\n",
      "traitlets==5.14.3\n",
      "typeguard==4.3.0\n",
      "typing-extensions==4.11.0\n",
      "tzdata==2023.3\n",
      "unicodedata2==15.1.0\n",
      "urllib3==2.2.2\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "wheel==0.43.0\n",
      "widgetsnbextension==4.0.10\n",
      "zipp==3.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ttanaka/miniconda3/envs/fresh_env/lib/python3.9/site-packages/shap/explainers/_kernel.py:640: DeprecationWarning: l1_reg='auto' is deprecated and in a future version the behavior will change from a conditional use of AIC to simply a fixed number of top features. Pass l1_reg='num_features(10)' to opt-in to the new default behaviour.\n",
      "  warnings.warn(\n",
      "/Users/ttanaka/miniconda3/envs/fresh_env/lib/python3.9/site-packages/shap/explainers/_kernel.py:640: DeprecationWarning: l1_reg='auto' is deprecated and in a future version the behavior will change from a conditional use of AIC to simply a fixed number of top features. Pass l1_reg='num_features(10)' to opt-in to the new default behaviour.\n",
      "  warnings.warn(\n",
      "/Users/ttanaka/miniconda3/envs/fresh_env/lib/python3.9/site-packages/shap/explainers/_kernel.py:640: DeprecationWarning: l1_reg='auto' is deprecated and in a future version the behavior will change from a conditional use of AIC to simply a fixed number of top features. Pass l1_reg='num_features(10)' to opt-in to the new default behaviour.\n",
      "  warnings.warn(\n",
      "/Users/ttanaka/miniconda3/envs/fresh_env/lib/python3.9/site-packages/shap/explainers/_kernel.py:640: DeprecationWarning: l1_reg='auto' is deprecated and in a future version the behavior will change from a conditional use of AIC to simply a fixed number of top features. Pass l1_reg='num_features(10)' to opt-in to the new default behaviour.\n",
      "  warnings.warn(\n",
      "/Users/ttanaka/miniconda3/envs/fresh_env/lib/python3.9/site-packages/shap/explainers/_kernel.py:640: DeprecationWarning: l1_reg='auto' is deprecated and in a future version the behavior will change from a conditional use of AIC to simply a fixed number of top features. Pass l1_reg='num_features(10)' to opt-in to the new default behaviour.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['USE_NUMBA'] = '0'  # Disable Numba\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create dummy data\n",
    "X = pd.DataFrame(np.random.rand(100, 5), columns=['A', 'B', 'C', 'D', 'E'])\n",
    "y = np.random.rand(100)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# SHAP\n",
    "try:\n",
    "    import shap\n",
    "    print(f\"SHAP version: {shap.__version__}\")\n",
    "    explainer = shap.TreeExplainer(rf_model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    print(\"\\nSHAP values for the first instance:\")\n",
    "    for feature, value in zip(X.columns, shap_values[0]):\n",
    "        print(f\"{feature}: {value:.4f}\")\n",
    "    print(\"SHAP analysis completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in SHAP analysis: {str(e)}\")\n",
    "\n",
    "# LIME\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular\n",
    "    print(f\"\\nLIME version: {lime.__version__}\")\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X.columns, mode=\"regression\")\n",
    "    exp = explainer.explain_instance(X_test.iloc[0], rf_model.predict)\n",
    "    print(\"\\nLIME explanation for the first instance:\")\n",
    "    for feature, value in exp.as_list():\n",
    "        print(f\"{feature}: {value:.4f}\")\n",
    "    print(\"LIME analysis completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in LIME analysis: {str(e)}\")\n",
    "\n",
    "# ELI5\n",
    "try:\n",
    "    import eli5\n",
    "    from eli5.sklearn import PermutationImportance\n",
    "    print(f\"\\nELI5 version: {eli5.__version__}\")\n",
    "    perm = PermutationImportance(rf_model, random_state=42).fit(X_test, y_test)\n",
    "    print(\"\\nELI5 feature importance:\")\n",
    "    print(eli5.format_as_text(eli5.explain_weights(perm, feature_names=X.columns.tolist())))\n",
    "    print(\"ELI5 analysis completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in ELI5 analysis: {str(e)}\")\n",
    "\n",
    "# InterpretML\n",
    "try:\n",
    "    from interpret import show\n",
    "    from interpret.blackbox import ShapKernel\n",
    "    print(\"\\nInterpretML analysis:\")\n",
    "    explainer = ShapKernel(rf_model.predict, X_train)\n",
    "    shap_values = explainer.explain_local(X_test[:5])\n",
    "    print(\"InterpretML SHAP values for the first 5 instances:\")\n",
    "    print(shap_values.data()[:5])\n",
    "    print(\"InterpretML analysis completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in InterpretML analysis: {str(e)}\")\n",
    "\n",
    "print(\"\\nInstalled packages:\")\n",
    "import pkg_resources\n",
    "installed_packages = [d for d in pkg_resources.working_set]\n",
    "for package in sorted(installed_packages, key=lambda x: x.key):\n",
    "    print(f\"{package.key}=={package.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48343757-b0ab-4ab9-a063-c4a962d94809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
